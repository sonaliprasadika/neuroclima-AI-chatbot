{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d19a06-4ab9-4416-9a38-f6462b865cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/ubuntu/myenv/lib/python3.10/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting scipy>=1.6.0\n",
      "  Using cached scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.0 scipy-1.14.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "445f0ee4-79fd-4003-ba93-f3cac9911cf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: transformers>=3.0.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from bert-score) (4.47.1)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/myenv/lib/python3.10/site-packages (from bert-score) (2.2.0)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "Requirement already satisfied: pandas>=1.0.1 in /home/ubuntu/myenv/lib/python3.10/site-packages (from bert-score) (2.2.3)\n",
      "Requirement already satisfied: requests in /home/ubuntu/myenv/lib/python3.10/site-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ubuntu/myenv/lib/python3.10/site-packages (from bert-score) (24.2)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /home/ubuntu/myenv/lib/python3.10/site-packages (from bert-score) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from bert-score) (2.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/myenv/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/myenv/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/myenv/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2024.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (12.3.1.170)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2.21.5)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (9.1.0.70)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.16.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.4.2)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ubuntu/myenv/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (10.3.5.147)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/myenv/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/myenv/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ubuntu/myenv/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.27.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ubuntu/myenv/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.21.0)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Requirement already satisfied: pillow>=8 in /home/ubuntu/myenv/lib/python3.10/site-packages (from matplotlib->bert-score) (11.0.0)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.55.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m:01\u001b[0mm\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/myenv/lib/python3.10/site-packages (from requests->bert-score) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/myenv/lib/python3.10/site-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/myenv/lib/python3.10/site-packages (from requests->bert-score) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/myenv/lib/python3.10/site-packages (from requests->bert-score) (3.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/myenv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib, bert-score\n",
      "Successfully installed bert-score-0.3.13 contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.3 kiwisolver-1.4.7 matplotlib-3.10.0 pyparsing-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5afdc8e9-141a-4521-9ae1-a954f2e68f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9066e5b2-a00b-4c7d-bfa2-8a7bbbf69aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    country  \\\n",
      "0      United Arab Emirates   \n",
      "1                Kazakhstan   \n",
      "2              Saudi Arabia   \n",
      "3  United States of America   \n",
      "4                   Finland   \n",
      "\n",
      "                                  policy_description  \\\n",
      "0  The National Hydrogen Strategy 2050 aims to su...   \n",
      "1  The code regulates activities which may have a...   \n",
      "2  Saudi Arabia aims to increase the share of nat...   \n",
      "3              Focused on better lighting solutions.   \n",
      "4  Investment proposal for areas with coal-fired ...   \n",
      "\n",
      "                                             Summary  \\\n",
      "0  The National Hydrogen Strategy 2050 aims to po...   \n",
      "1  A code requiring the largest polluters to adop...   \n",
      "2  Saudi Arabia aims for 50% of electricity from ...   \n",
      "3  Focus on enhancing lighting solutions for ener...   \n",
      "4  Proposal for investing in regions with coal pl...   \n",
      "\n",
      "                             facebook/bart-large-cnn  \\\n",
      "0  The National Hydrogen Strategy 2050 aims to su...   \n",
      "1  The code regulates activities which may have a...   \n",
      "2  Saudi Arabia aims to increase the share of nat...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                 google/flan-t5-base  \\\n",
      "0  The strategy aims to support low-carbon local ...   \n",
      "1                                The Code of Conduct   \n",
      "2  Saudi Arabia aims to increase the share of nat...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                            T5-large  \n",
      "0  the national hydrogen Strategy 2050 aims to su...  \n",
      "1  the code regulates activities which may have a...  \n",
      "2  Saudi Arabia aims to increase the share of nat...  \n",
      "3                                                NaN  \n",
      "4                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the data\n",
    "df = pd.read_csv('summery_training.csv', encoding='latin1')\n",
    "print(df.head())\n",
    "\n",
    "# Extract original policy descriptions\n",
    "original_docs = df['policy_description'].tolist()\n",
    "\n",
    "# Extract GPT-4o-mini summaries\n",
    "gpt_summaries = df['Summary'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70cebbdc-5da5-4e35-a3e9-0b788ce083f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(\"./flan-t5-policy-finetune\")\n",
    "summarizer_tokenizer = AutoTokenizer.from_pretrained(\"./flan-t5-policy-finetune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e08a3820-0bcf-40d5-9650-98f031c08d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to summarize documents using your local model\n",
    "def summarize_documents(docs, max_length=200):  # Increase max_length for more detailed summaries\n",
    "    summaries = []\n",
    "    for doc in docs:\n",
    "        input_text = \"summarize: \" + doc\n",
    "        inputs = summarizer_tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "        summary_ids = summarizer_model.generate(\n",
    "            inputs,\n",
    "            max_length=max_length,\n",
    "            min_length=100,  # Increase min_length for more detailed summaries\n",
    "            length_penalty=1.5,  # Adjust length penalty to encourage longer summaries\n",
    "            num_beams=6,  # Increase num_beams for better quality\n",
    "            early_stopping=True\n",
    "        )\n",
    "        summary = summarizer_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        summaries.append(summary)\n",
    "    return summaries\n",
    "\n",
    "# Generate summaries using your local model\n",
    "local_summaries = summarize_documents(original_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f544e93e-b566-44b6-92cb-3ed2f9d9902f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between GPT-4o-mini and Local Model Summaries: 0.3637\n",
      "Mean Squared Error of summary lengths: 180642.0000\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate cosine similarity between two lists of summaries\n",
    "def calculate_cosine_similarity(list1, list2):\n",
    "    vectorizer = TfidfVectorizer().fit_transform(list1 + list2)\n",
    "    vectors = vectorizer.toarray()\n",
    "    cosine_sim = cosine_similarity(vectors[:len(list1)], vectors[len(list1):])\n",
    "    return cosine_sim.diagonal().mean()\n",
    "\n",
    "# Calculate and print cosine similarity between GPT-4o-mini summaries and local model summaries\n",
    "cosine_sim = calculate_cosine_similarity(gpt_summaries, local_summaries)\n",
    "print(f'Cosine Similarity between GPT-4o-mini and Local Model Summaries: {cosine_sim:.4f}')\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) between GPT-4o-mini and Local Model summaries length\n",
    "mse_length = mean_squared_error([len(s) for s in gpt_summaries], [len(s) for s in local_summaries])\n",
    "print(f'Mean Squared Error of summary lengths: {mse_length:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40693d5a-9ac6-4055-bc30-29ec143e18f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score between GPT-4o-mini and Local Model Summaries: 0.0203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/myenv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/ubuntu/myenv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/ubuntu/myenv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate BLEU score\n",
    "def calculate_bleu_score(reference_summaries, generated_summaries):\n",
    "    bleu_scores = []\n",
    "    for reference, generated in zip(reference_summaries, generated_summaries):\n",
    "        reference_tokens = [reference.split()]\n",
    "        generated_tokens = generated.split()\n",
    "        score = sentence_bleu(reference_tokens, generated_tokens)\n",
    "        bleu_scores.append(score)\n",
    "    return sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "# Calculate and print BLEU score\n",
    "bleu_score = calculate_bleu_score(gpt_summaries, local_summaries)\n",
    "print(f'BLEU Score between GPT-4o-mini and Local Model Summaries: {bleu_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28d41f36-b0b0-46d7-a67a-afcbc57e3c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores:\n",
      "ROUGE1: 0.2256\n",
      "ROUGE2: 0.1071\n",
      "ROUGEL: 0.1877\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROUGE scores\n",
    "def calculate_rouge_scores(gpt_summaries, local_summaries):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "    \n",
    "    for gpt_summary, local_summary in zip(gpt_summaries, local_summaries):\n",
    "        score = scorer.score(local_summary, gpt_summary)\n",
    "        for key in scores.keys():\n",
    "            scores[key].append(score[key].fmeasure)\n",
    "    \n",
    "    avg_scores = {key: sum(values) / len(values) for key, values in scores.items()}\n",
    "    return avg_scores\n",
    "\n",
    "# Calculate and print ROUGE scores between GPT-4o-mini summaries and local model summaries\n",
    "rouge_scores = calculate_rouge_scores(gpt_summaries, local_summaries)\n",
    "print(f'ROUGE Scores:')\n",
    "for metric, score in rouge_scores.items():\n",
    "    print(f'{metric.upper()}: {score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30fac6d8-33b0-4de3-ab24-218374b1c44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore Results:\n",
      "Precision: 0.5129\n",
      "Recall: 0.7018\n",
      "F1 Score: 0.5874\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "# Function to calculate BERTScore\n",
    "def calculate_bert_score(reference_summaries, candidate_summaries, model_name='bert-base-uncased'):\n",
    "    P, R, F1 = score(candidate_summaries, reference_summaries, model_type=model_name, lang=\"en\")\n",
    "    avg_f1 = F1.mean().item()\n",
    "    return avg_f1, P.mean().item(), R.mean().item()\n",
    "\n",
    "# Calculate BERTScore between GPT-4o-mini summaries and Local Model summaries\n",
    "bert_avg_f1, bert_precision, bert_recall = calculate_bert_score(gpt_summaries, local_summaries)\n",
    "\n",
    "# Print the BERTScore results\n",
    "print(f\"BERTScore Results:\")\n",
    "print(f\"Precision: {bert_precision:.4f}\")\n",
    "print(f\"Recall: {bert_recall:.4f}\")\n",
    "print(f\"F1 Score: {bert_avg_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f479a3af-9bf2-4f41-8c8c-452caaf29a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
