{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e7c50c0-4118-433b-9933-d18d432dc688",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in /home/ubuntu/myenv/lib/python3.10/site-packages (0.3.13)\n",
      "Requirement already satisfied: transformers in /home/ubuntu/myenv/lib/python3.10/site-packages (4.47.1)\n",
      "Requirement already satisfied: datasets in /home/ubuntu/myenv/lib/python3.10/site-packages (3.2.0)\n",
      "Requirement already satisfied: rouge-score in /home/ubuntu/myenv/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in /home/ubuntu/myenv/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: tensorboard in /home/ubuntu/myenv/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: py7zr in /home/ubuntu/myenv/lib/python3.10/site-packages (0.22.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/ubuntu/myenv/lib/python3.10/site-packages (from pytesseract) (24.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from pytesseract) (11.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/myenv/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ubuntu/myenv/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/myenv/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: requests in /home/ubuntu/myenv/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ubuntu/myenv/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/myenv/lib/python3.10/site-packages (from transformers) (2.2.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/myenv/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/myenv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/ubuntu/myenv/lib/python3.10/site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/myenv/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ubuntu/myenv/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/myenv/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: absl-py in /home/ubuntu/myenv/lib/python3.10/site-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in /home/ubuntu/myenv/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/myenv/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from tensorboard) (59.6.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/ubuntu/myenv/lib/python3.10/site-packages (from tensorboard) (1.68.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ubuntu/myenv/lib/python3.10/site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /home/ubuntu/myenv/lib/python3.10/site-packages (from tensorboard) (5.29.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ubuntu/myenv/lib/python3.10/site-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from py7zr) (1.0.2)\n",
      "Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from py7zr) (1.1.0)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/myenv/lib/python3.10/site-packages (from py7zr) (6.1.1)\n",
      "Requirement already satisfied: texttable in /home/ubuntu/myenv/lib/python3.10/site-packages (from py7zr) (1.7.0)\n",
      "Requirement already satisfied: pyzstd>=0.15.9 in /home/ubuntu/myenv/lib/python3.10/site-packages (from py7zr) (0.16.2)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /home/ubuntu/myenv/lib/python3.10/site-packages (from py7zr) (0.2.3)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from py7zr) (1.1.0)\n",
      "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from py7zr) (1.0.0)\n",
      "Requirement already satisfied: pycryptodomex>=3.16.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from py7zr) (3.21.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/myenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/myenv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/myenv/lib/python3.10/site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/myenv/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/myenv/lib/python3.10/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ubuntu/myenv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/myenv/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/myenv/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/myenv/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract transformers datasets rouge-score nltk tensorboard py7zr --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "176cbad6-2ce5-40ff-9a7c-b7eb2381ce73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "git-lfs is already the newest version (3.0.2-1ubuntu0.3).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 60 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# install git-fls for pushing model and logs to the hugging face hub\n",
    "!sudo apt-get install git-lfs --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833a52c3-a4ec-4a6c-86ec-4a0430074105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "997d1f29-af0d-4b58-a466-581ff075a3b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    country  \\\n",
      "0      United Arab Emirates   \n",
      "1                Kazakhstan   \n",
      "2              Saudi Arabia   \n",
      "3  United States of America   \n",
      "4                   Finland   \n",
      "\n",
      "                                  policy_description  \\\n",
      "0  The National Hydrogen Strategy 2050 aims to su...   \n",
      "1  The code regulates activities which may have a...   \n",
      "2  Saudi Arabia aims to increase the share of nat...   \n",
      "3              Focused on better lighting solutions.   \n",
      "4  Investment proposal for areas with coal-fired ...   \n",
      "\n",
      "                                             Summary  \\\n",
      "0  The National Hydrogen Strategy 2050 aims to po...   \n",
      "1  A code requiring the largest polluters to adop...   \n",
      "2  Saudi Arabia aims for 50% of electricity from ...   \n",
      "3  Focus on enhancing lighting solutions for ener...   \n",
      "4  Proposal for investing in regions with coal pl...   \n",
      "\n",
      "                             facebook/bart-large-cnn  \\\n",
      "0  The National Hydrogen Strategy 2050 aims to su...   \n",
      "1  The code regulates activities which may have a...   \n",
      "2  Saudi Arabia aims to increase the share of nat...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                 google/flan-t5-base  \\\n",
      "0  The strategy aims to support low-carbon local ...   \n",
      "1                                The Code of Conduct   \n",
      "2  Saudi Arabia aims to increase the share of nat...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                            T5-large  \n",
      "0  the national hydrogen Strategy 2050 aims to su...  \n",
      "1  the code regulates activities which may have a...  \n",
      "2  Saudi Arabia aims to increase the share of nat...  \n",
      "3                                                NaN  \n",
      "4                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the data\n",
    "data = pd.read_csv('summery_training.csv', encoding='latin1')\n",
    "print(data.head())\n",
    "\n",
    "# Convert to Hugging Face Dataset format\n",
    "dataset = Dataset.from_pandas(data)\n",
    "\n",
    "# Step 2: Tokenize the data\n",
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288e221b-068c-4987-87e7-fbe862ae17d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/myenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3953: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|█████████████████████| 9/9 [00:00<00:00, 130.27 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Preprocess the data\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the policy description (input)\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"policy_description\"],\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    # Tokenize the summary (target labels)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"Summary\"],\n",
    "            max_length=150,  # Limit the length of the summary to avoid excessively long labels\n",
    "            truncation=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "\n",
    "    # Assign labels to the tokenized input\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Apply tokenization to the dataset\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3689bd0e-9b54-46b6-98a6-926316fb3e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/myenv/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Load the model and set up training arguments\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./flan-t5-policy-finetune\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=3,\n",
    "    save_total_limit=3,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "614f281a-2a98-4699-acb5-17834ba1f775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2812911/1522892131.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='0' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [0/3 : < :, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>39.849087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=0, training_loss=112451.98822021484, metrics={'train_runtime': 195.8287, 'train_samples_per_second': 0.138, 'train_steps_per_second': 0.015, 'total_flos': 4108544114688.0, 'train_loss': 112451.98822021484, 'epoch': 0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Set up the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "557f9909-791f-4038-981e-fa1f210575d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 39.84908676147461,\n",
       " 'eval_runtime': 9.1868,\n",
       " 'eval_samples_per_second': 0.98,\n",
       " 'eval_steps_per_second': 0.544,\n",
       " 'epoch': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7: Evaluate trained model\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2f6b094-66db-4b8b-8256-8e9910787a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./flan-t5-policy-finetune/tokenizer_config.json',\n",
       " './flan-t5-policy-finetune/special_tokens_map.json',\n",
       " './flan-t5-policy-finetune/tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7: Save the trained model\n",
    "model.save_pretrained(\"./flan-t5-policy-finetune\")\n",
    "tokenizer.save_pretrained(\"./flan-t5-policy-finetune\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2c526fa-5bcf-41c8-ae80-606afc35ac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/myenv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revision 1-E/2017 establishes a discount of up to 20% on electricity prices for energy-intensive industries.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./flan-t5-policy-finetune\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./flan-t5-policy-finetune\")\n",
    "\n",
    "# Function to generate a policy summary\n",
    "def generate_policy_summary(policy_description):\n",
    "    inputs = tokenizer(\n",
    "        policy_description,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "    # Generate summaries\n",
    "    summary_ids = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=150,          # Adjust the max length as needed\n",
    "        num_beams=5,             # Increase beams for better quality\n",
    "        early_stopping=True,\n",
    "        temperature=0.7,         # Adjust for diversity in the output\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    \n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example policy description\n",
    "policy_description = \"Resolution 1-E/2017 establishes a discount of up to 20% on electricity prices for energy-intensive industries. Provision 3/2018 (2018, as part of Joint Resolution 1-E/2017) Companies that want to benefit from reduced electicity price have to implement the ISO norm 50001 on energy management systems (i.e. develop a plan of action for energy management, establish targets for energy performance, and define indicators to monitor progress)\"\n",
    "\n",
    "# Generate the summary\n",
    "summary = generate_policy_summary(policy_description)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315151dc-2185-45b5-a82b-fa4f4f14ba2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
